"""
-----------------------------------------------------------------------------------------------------------------------------------------------------

Â© Copyright 2022, California, Department of Motor Vehicle, all rights reserved.
The source code and all its associated artifacts belong to the California Department of Motor Vehicle (CA, DMV), and no one has any ownership
and control over this source code and its belongings. Any attempt to copy the source code or repurpose the source code and lead to criminal
prosecution. Don't hesitate to contact DMV for further information on this copyright statement.

Release Notes and Development Platform:
The source code was developed on the Google Cloud platform using Google Cloud Functions serverless computing architecture. The Cloud
Functions gen 2 version automatically deploys the cloud function on Google Cloud Run as a service under the same name as the Cloud
Functions. The initial version of this code was created to quickly demonstrate the role of MLOps in the ELP process and to create an MVP. Later,
this code will be optimized, and Python OOP concepts will be introduced to increase the code reusability and efficiency.
____________________________________________________________________________________________________________
Development Platform                | Developer       | Reviewer   | Release  | Version  | Date
____________________________________|_________________|____________|__________|__________|__________________
Google Cloud Serverless Computing   | DMV Consultant  | Ajay Gupta | Initial  | 1.0      | 09/18/2022

-----------------------------------------------------------------------------------------------------------------------------------------------------

"""


import json
import traceback
import os
import pandas as pd

from DMV_ELP_Request_PreValidation import Pre_Request_Validation
from DMV_ELP_Public_Profanity_Validation import Profanity_Words_Check
from DMV_ELP_GuideLine_FWord_Validation import FWord_Validation
from DMV_ELP_Previously_Denied_Config_Validation import Previously_Denied_Configuration_Validation

from DMV_ELP_Pattern_Denial import Pattern_Denial

# from DMV_ELP_BERT_Test import BERT_Model_Result
from DMV_ELP_BERT_Model_Prediction import BERT_Model_Result
from DMV_ELP_LSTM_Model_Prediction import LSTM_Model_Result
from DMV_ELP_Get_License_Plate_Code import GetPlateCode
from DMV_ELP_Get_Max_Plate_Count import GetMaxPlateTypeCount,GetMaxPlateTypeCountPartial
from DMV_ChatGPT_Recommendation import ELP_Recommendation

def ELP_Validation(request):
    
    vAR_partial_file_name = ""
    vAR_partial_file_date = ""
    vAR_error_message = {}
    request_json = request.get_json()
    print('request_json - ',request_json)
    print('request_json type- ',type(request_json))
    if 'PARTIAL_FILE_NAME' in request_json.keys() and 'PARTIAL_FILE_DATE' in request_json.keys():
        vAR_partial_file_name = request_json['PARTIAL_FILE_NAME']
        vAR_partial_file_date = request_json['PARTIAL_FILE_DATE']
        # vAR_max_plate_type_count = GetMaxPlateTypeCountPartial(vAR_partial_file_name,vAR_partial_file_date)
        
        del request_json['PARTIAL_FILE_NAME']
        del request_json['PARTIAL_FILE_DATE']
    else:
        pass
        # vAR_max_plate_type_count = GetMaxPlateTypeCount()


    response_json = request_json.copy()
    


    try:
        # To resolve container error(TypeError: Descriptors cannot not be created directly)
        os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'

        
        vAR_input_text = request_json['LICENSE_PLATE_CONFIG'].upper()
        
        

        
        vAR_result_message = ""
        
        vAR_error_message = Pre_Request_Validation(request_json,vAR_partial_file_name,vAR_partial_file_date)

        vAR_platecode_error_message = ""
        # vAR_plate_code,vAR_platecode_error_message = GetPlateCode(vAR_license_plate_desc)
        
        
        
        if len(vAR_error_message["Error Message"])==0:
            if len(vAR_platecode_error_message)>0:
                vAR_error_message['Error Message'] = vAR_platecode_error_message

            response_json["ERROR_MESSAGE"] = vAR_error_message["Error Message"]
            
            # vAR_result,vAR_result_data,vAR_result_target_sum = LSTM_Model_Result(vAR_input_text)
            # vAR_result_data = str(vAR_result_data.to_json(orient='records'))
            # if not vAR_result:
            #     print('Config denied by RNN Model - ',vAR_input_text)
            #     vAR_recommendation = "Denied"
            #     vAR_recommendation_reason = "Highest Profanity category probability should be below the threshold value(0.5)"
                
            #     response_json["RNN"] = {"PROFANITY_CLASSIFICATION":json.loads(str(vAR_result_data)),"SUM_OF_ALL_CATEGORIES":float(vAR_result_target_sum),"RECOMMENDATION":vAR_recommendation,"REASON":vAR_recommendation_reason,"MODEL":"RNN"}

            #     print('Response from RNN Denied - ',response_json)

                
            # else:

            #     vAR_recommendation = "Accepted"
            #     vAR_recommendation_reason = "Since Highest Profanity category probability less than the threshold value(0.5), configuration accepted"

                
            #     response_json["RNN"] = {"PROFANITY_CLASSIFICATION":json.loads(str(vAR_result_data)),"SUM_OF_ALL_CATEGORIES":float(vAR_result_target_sum),"RECOMMENDATION":vAR_recommendation,"REASON":vAR_recommendation_reason,"MODEL":"RNN"}

            #     print('Response from RNN Accepted- ',response_json)
                
            # GPT Model Call

            result_json = ChatGPT_Recommendation(vAR_input_text)
            response_json["GPT"] = result_json
            print('Result json from GPT(till GPT) - ',response_json)

            print('Response after GPT- ',response_json)

            return response_json

                

            
                

                
                
            # elif vAR_model.upper()=='BERT':

            #     vAR_result,vAR_result_data,vAR_result_target_sum = BERT_Model_Result(vAR_input_text)

            #     if not vAR_result:
            #         vAR_recommendation = "Denied"
            #         vAR_recommendation_reason = "Highest Profanity category probability should be below the threshold value(0.5)"
            #         response_json["RECOMMENDATION"] = vAR_recommendation
            #         response_json["REASON"] = vAR_recommendation_reason
            #     else:
            #         vAR_recommendation = "Accepted"
            #         vAR_recommendation_reason = "Since Highest Profanity category probability less than the threshold value(0.5), configuration accepted"
            #         response_json["RECOMMENDATION"] = vAR_recommendation
            #         response_json["REASON"] = vAR_recommendation_reason
                
            #     vAR_result_data = str(vAR_result_data.to_json(orient='records'))

            
            #     response_json["MODEL"] = vAR_model
            #     response_json["MODEL_PREDICTION"] = {"PROFANITY_CLASSIFICATION":json.loads(str(vAR_result_data)),"SUM_OF_ALL_CATEGORIES":float(vAR_result_target_sum)}
            #     print('BERT response json - ',response_json)
            #     return response_json

            # elif vAR_model.upper()=='GPT':

            #     result_json = ChatGPT_Recommendation(vAR_input_text)



            
                
            

        else:
            response_json["ERROR_MESSAGE"] = vAR_error_message["Error Message"]
            return response_json

    except BaseException as e:
        print('In Error Block - '+str(e))
        print('Error Traceback4 - '+str(traceback.print_exc()))
        response_json["ERROR_MESSAGE"] = '### '+str(e)
        return response_json



def ChatGPT_Recommendation(vAR_input_text):
    try:
        response_json = {}

        vAR_response = ELP_Recommendation(vAR_input_text)

        vAR_dict1_start_index = vAR_response.index('{')
        vAR_dict1_end_index = vAR_response.index('}')


        vAR_dict2_start_index = vAR_response.rfind('{')
        vAR_dict2_end_index = vAR_response.rfind('}')

        vAR_result_dict = vAR_response[vAR_dict1_start_index:vAR_dict1_end_index+1]
        vAR_conclusion_dict = vAR_response[vAR_dict2_start_index:vAR_dict2_end_index+1]

        vAR_result_df = pd.DataFrame(json.loads(vAR_result_dict))
        vAR_conclusion_df = pd.DataFrame(json.loads(vAR_conclusion_dict))

        response_json["MODEL"] = "GPT"
        response_json["RECOMMENDATION"] = vAR_conclusion_df["Conclusion"][0]
        response_json["REASON"] = vAR_conclusion_df["Conclusion Reason"][0] 
        response_json["RECOMMENDED_CONFIGURATION"] = vAR_conclusion_df["Recommended Configuration"][0]
        response_json["RECOMMENDATION_REASON"] = vAR_conclusion_df["Recommendation Reason"][0]

        response_json["SEVERE_TOXIC_REASON"] = vAR_result_df["Reason"][0]
        response_json["OBSCENE_REASON"] = vAR_result_df["Reason"][1]
        response_json["INSULT_REASON"] = vAR_result_df["Reason"][2]
        response_json["HATE_REASON"] = vAR_result_df["Reason"][3]
        response_json["TOXIC_REASON"] = vAR_result_df["Reason"][4]
        response_json["THREAT_REASON"] = vAR_result_df["Reason"][5]

        response_json["SEVERE_TOXIC"] = vAR_result_df["Probability"][0]
        response_json["OBSCENE"] = vAR_result_df["Probability"][1]
        response_json["INSULT"] = vAR_result_df["Probability"][2]
        response_json["IDENTITY_HATE"] = vAR_result_df["Probability"][3]
        response_json["TOXIC"] = vAR_result_df["Probability"][4]
        response_json["THREAT"] = vAR_result_df["Probability"][5]

        response_json["OVERALL_SCORE"] = None

        print('GPT response json - ',response_json)
        return response_json

    except BaseException as e:
        raise Exception("GPT Model Error - "+str(e))

